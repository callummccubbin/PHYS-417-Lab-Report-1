# Lab 1 Report: 
## Data Preparation Techniques for Machine Learning
# Import necessary libraries

%matplotlib inline
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from IPython.display import Image # For displaying images in colab jupyter cell
Image('lab1_exercise1.PNG', width = 1000)
# Load the dataset (.csv) using pandas package

CMS_calori_dataset = pd.read_csv('hgcal.csv')

# .head directive on the panda dataframe displays the first n-rows

CMS_calori_dataset.head(n = 10)
# Convert the panda dataframe into numpy 2D array

CMS_calori_dataset_np = CMS_calori_dataset.to_numpy()

# The converted numpy array has the dimension of 420 (rows) x 8 (columns)

print(CMS_calori_dataset_np.shape)
# Extract only x, y, z, eta, phi and energy columns from the dataset and stack them along column direction
# Name this new 2D array CMS_calori_dataset_np_sub. 
# The array should have dimension 420 (rows) x 6 (columns)

# select all rows, but only the columns in indices 1 thru 7, which correspond to the requested columns in the dataset.
CMS_calori_dataset_np_sub = CMS_calori_dataset_np[:, 1:7]

# print(CMS_calori_dataset_np_sub)

# the array has 420 rows and 6 columns.
print(CMS_calori_dataset_np_sub)
# Create the scaling function

#The columns will be scaled independent of each other. So let's make a subfunction that scales a single column.

def scale_data(arr):
    scaled_data = arr.copy()

    def scale_column(col):
        scaled_column = col - np.mean(col)

        scaled_column = scaled_column / np.std(scaled_column)
        return scaled_column

    # arr.shape[1] is the number of columns we want to loop through
    for i in range(0, arr.shape[1]):
        print()
        scaled_data[:, i] = scale_column(arr[:, i])

    # do this to each column

    
    return scaled_data
# Test the function with CMS_calori_dataset_np_sub
print(CMS_calori_dataset_np_sub[0, 1])

CMS_calori_dataset_np_sub_scaled = scale_data(CMS_calori_dataset_np_sub)

print(CMS_calori_dataset_np_sub_scaled)
# Confirm the data is scaled for 'x' column

plt.figure(figsize = (10, 5))

plt.hist(CMS_calori_dataset_np_sub_scaled[:, 0], bins = 20, facecolor = 'grey', edgecolor = 'black', linewidth = 2)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

# Add proper x-label and y-label

plt.xlabel('scaled x')
plt.ylabel('count')

plt.show()
# Confirm the data is scaled for 'energy' column

plt.figure(figsize = (10, 5))

plt.hist(CMS_calori_dataset_np_sub_scaled[:, 5], bins = 20, facecolor = 'grey', edgecolor = 'black', linewidth = 2)
plt.xticks(fontsize=14)
plt.yticks(fontsize=14)

# Add proper x-label and y-label 

plt.xlabel('scaled energy')
plt.ylabel('count')

plt.show()
### Expected histogram outputs - Feel free to style your plot differently
Image('lab1_e1_expected_outputs.PNG', width = 1000)
Image('lab1_exercise2.PNG', width = 1000)
# Create the splitting function

def split_data(arr, split_proportions, axis):
    
    # we have no guarantee that the split proportions will split the array into sub arrays with integer numbers of subarrays.
    # we need to make sure that the function never drops a subarray.
    # we also may receive an array of split proportions that doesn't add up to 1. We can fix these at the same time.

    print(arr.shape[axis])
    split = np.multiply(split_proportions, arr.shape[axis])

    # We need the split function to be all integers!
    # For some reason np.round doesn't convert to integers, so they are cast to integers instead.
    split = [int(v) for v in split]
    print(split)
    # We also don't want to drop any subarrays. So, if the sum of the split array doens't add up to the total number,
    # we add the difference to the last element. 
    split[-1] = split[-1] + arr.shape[axis] - np.sum(split)

    print(split)
    # now we input the massaged split array into np.split, noting that np.split takes its split value as positions, so we need to
    # convert to the positions by cumulatively summing over it.
    split_data_list = np.split(arr, np.cumsum(split), axis)

    # Returns a list of numpy sub-arrays according to split proportions
    return split_data_list
# Test your split function against scaled CMS Calorimieter dataset from exercise 1

sub_data_list_1 = split_data(arr = CMS_calori_dataset_np_sub_scaled, split_proportions = [0.6, 0.2, 0.2], axis = 0)
# Confirm that dataset has been split into correct shapes
# The correct dimensions should be (252, 6) (84, 6) (84, 6)

print(sub_data_list_1[0].shape, sub_data_list_1[1].shape, sub_data_list_1[2].shape)
# Test your split function against scaled CMS Calorimieter dataset from exercise 1

sub_data_list_2 = split_data(arr = CMS_calori_dataset_np_sub_scaled, 
                                                split_proportions = [0.5, 0.5], axis = 1)
# Confirm that dataset has been split into correct shapes
# The correct dimensions should be (420, 3) (420, 3)

print(sub_data_list_2[0].shape, sub_data_list_2[1].shape)
